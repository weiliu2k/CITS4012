
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4. Neural Machine Translation Model &#8212; CITS4012 Natural Language Processing</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e8f53015daec13862f6db5e763c41738.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="6. Neural Machine Translation Model" href="NMT_scheduled_sampling.html" />
    <link rel="prev" title="&lt;no title&gt;" href="PackedSequence.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/logo_ntlp.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">CITS4012 Natural Language Processing</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   HOME
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../basics/intro.html">
   Lab 01: Conda Environment and Python Refresher
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/installation.html">
     1. CITS4012 Base Environment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/installation_misc.html">
     2. CITS4012 MISC Enviornment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lab_machines.html">
     3. Use Lab Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/python_review.html">
     4. Python Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/iterables.html">
     5. Iterables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/numpy.html">
     6. Numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/matplotlib.html">
     7. Matplotlib
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../NLTK/intro.html">
   Lab02: NLTK
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/start.html">
     1. Starting with NLTK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/closer_look.html">
     2. A Closer Look at Python: Texts as Lists of Words
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/computing.html">
     3. Computing with Language: Simple Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/take_control.html">
     4. Back to Python: Making Decisions and Taking Control
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLTK/exercises.html">
     5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../spacy/intro.html">
   Lab03: spaCy NLP pipelines
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/container.html">
     1. Container Objects in spaCy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/pipeline.html">
     2. NLP Pipelines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/patterns.html">
     3. Finding Patterns
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/telegram.html">
     4. Your first chatbot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../spacy/exercise.html">
     5. Exercise
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../gensim/intro.html">
   Lab04: Count-Based Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../gensim/tf-idf.html">
     1. TF-IDF in scikit-learn and Gensim
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../gensim/classification.html">
     2. Document Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../nn/intro.html">
   Lab05: Introduction to Neural Networks and Pytorch
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../nn/linear_model_numpy.html">
     1. Linear Models in Numpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nn/tensors.html">
     2. Introduction to Pytorch Tensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nn/linear_model_pytorch.html">
     3. Linear Models in Pytorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../pytorch/intro.html">
   Lab06: Neural Network Building Blocks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/activations.html">
     1. Activation Functions and their derivatives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/loss.html">
     2. Loss Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/computational_graph.html">
     3. Dynamic Computational Graph in PyTorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pytorch/nn_oop.html">
     4. Neural Networks in PyTorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../embeddings/intro.html">
   Lab07: Word Embeddings
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../embeddings/svd.html">
     1. Word Vectors from Word-Word Coocurrence Matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../embeddings/glove.html">
     2. GloVe: Global Vectors for Word Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../embeddings/word2vec.html">
     3. Word2Vec
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../classification/intro.html">
   Lab08: Document Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/perceptron.html">
     1. Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/data_prep.html">
     2. Dataset and DataLoader
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/yelp_preprocessing.html">
     3. Yelp Dataset at a glance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../classification/yelp.html">
     4. Yelp Review Dataset - Document Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../cnn/intro.html">
   Lab09: CNN for NLP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/dataset_frankenstein_processing.html">
     1. Frankenstein Dataset At a Glance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/CBOW.html">
     2. Learning Embeddings with Continuous Bag of Words (CBOW)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/convolution.html">
     3. Convolution Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/dataset_AG_News_processing.html">
     4. AG News Dataset at A Glance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cnn/Document_Classification_with_CNN.html">
     5. Using CNN for Document Classification with Embeddings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../rnn/intro.html">
   Lab10: RNN for NLP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../rnn/rnn.html">
     1. Recurrent Neural Networks - Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../rnn/elman_rnn_square.html">
     2. Classifying Synthetic Sequences - The Square Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../rnn/Surname_Dataset.html">
     3. Surname Dataset Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../rnn/Surname_Classification.html">
     4. Surname Classification with RNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../LSTM/intro.html">
   Lab11: GRU, LSTM and Seq2Seq
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../LSTM/gru.html">
     1. Gated Recurrent Units (GRUs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../LSTM/lstm.html">
     2. Long Short Term Memories (LSTMs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../LSTM/gru_lstm_square.html">
     3. The Square Model Using GRU and LSTM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../LSTM/seq2seq.html">
     4. Sequence to Sequence Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../LSTM/Surname_Generation_Unconditioned.html">
     5. Surname Generation - Unconditioned
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../LSTM/Surname_Generation_Conditioned.html">
     6. Surname Generation Conditioned
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="intro.html">
   Lab12: Sequence to Sequence Learning with Attention
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="attention.html">
     1. Attention Mechanism
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="self_attention.html">
     2. Self-Attention
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="nmt_data_processing.html">
     3. Neual Machine Translation
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     4. Neural Machine Translation Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NMT_scheduled_sampling.html">
     6. Neural Machine Translation Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://drive.google.com/file/d/1AQxhGLhoHE162HALo1NkgdaN-LVY4QWo/view?usp=sharing">
   data.zip
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/weiliu2k/CITS4012/raw/master/CITS4012LabBook.pdf">
   PDF
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/attention/NMT_No_Sampling.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/attention/NMT_No_Sampling.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   4. Neural Machine Translation Model
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-routine-and-bookkeeping-functions">
   5. Training Routine and Bookkeeping Functions
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">string</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils.rnn</span> <span class="kn">import</span> <span class="n">pack_padded_sequence</span><span class="p">,</span> <span class="n">pad_packed_sequence</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm_notebook</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Vocabulary</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Class to process text and extract vocabulary for mapping&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_to_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            token_to_idx (dict): a pre-existing map of tokens to indices</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">token_to_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">token_to_idx</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span> <span class="o">=</span> <span class="n">token_to_idx</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_token</span> <span class="o">=</span> <span class="p">{</span><span class="n">idx</span><span class="p">:</span> <span class="n">token</span> 
                              <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        
    <span class="k">def</span> <span class="nf">to_serializable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; returns a dictionary that can be serialized &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;token_to_idx&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">}</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_serializable</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">contents</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; instantiates the Vocabulary from a serialized dictionary &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">contents</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update mapping dicts based on the token.</span>

<span class="sd">        Args:</span>
<span class="sd">            token (str): the item to add into the Vocabulary</span>
<span class="sd">        Returns:</span>
<span class="sd">            index (int): the integer corresponding to the token</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">index</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_token</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">token</span>
        <span class="k">return</span> <span class="n">index</span>
            
    <span class="k">def</span> <span class="nf">add_many</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add a list of tokens into the Vocabulary</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            tokens (list): a list of string tokens</span>
<span class="sd">        Returns:</span>
<span class="sd">            indices (list): a list of indices corresponding to the tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">add_token</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">lookup_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieve the index associated with the token </span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            token (str): the token to look up </span>
<span class="sd">        Returns:</span>
<span class="sd">            index (int): the index corresponding to the token</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">lookup_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the token associated with the index</span>
<span class="sd">        </span>
<span class="sd">        Args: </span>
<span class="sd">            index (int): the index to look up</span>
<span class="sd">        Returns:</span>
<span class="sd">            token (str): the token corresponding to the index</span>
<span class="sd">        Raises:</span>
<span class="sd">            KeyError: if the index is not in the Vocabulary</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">index</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_token</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;the index (</span><span class="si">%d</span><span class="s2">) is not in the Vocabulary&quot;</span> <span class="o">%</span> <span class="n">index</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_token</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;Vocabulary(size=</span><span class="si">%d</span><span class="s2">)&gt;&quot;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SequenceVocabulary</span><span class="p">(</span><span class="n">Vocabulary</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_to_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">unk_token</span><span class="o">=</span><span class="s2">&quot;&lt;UNK&gt;&quot;</span><span class="p">,</span>
                 <span class="n">mask_token</span><span class="o">=</span><span class="s2">&quot;&lt;MASK&gt;&quot;</span><span class="p">,</span> <span class="n">begin_seq_token</span><span class="o">=</span><span class="s2">&quot;&lt;BEGIN&gt;&quot;</span><span class="p">,</span>
                 <span class="n">end_seq_token</span><span class="o">=</span><span class="s2">&quot;&lt;END&gt;&quot;</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">SequenceVocabulary</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">token_to_idx</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_mask_token</span> <span class="o">=</span> <span class="n">mask_token</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_unk_token</span> <span class="o">=</span> <span class="n">unk_token</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_begin_seq_token</span> <span class="o">=</span> <span class="n">begin_seq_token</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_end_seq_token</span> <span class="o">=</span> <span class="n">end_seq_token</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mask_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_token</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mask_token</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_token</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_unk_token</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">begin_seq_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_token</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_begin_seq_token</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_seq_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_token</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_end_seq_token</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">to_serializable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">contents</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">SequenceVocabulary</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">to_serializable</span><span class="p">()</span>
        <span class="n">contents</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;unk_token&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unk_token</span><span class="p">,</span>
                         <span class="s1">&#39;mask_token&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask_token</span><span class="p">,</span>
                         <span class="s1">&#39;begin_seq_token&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_begin_seq_token</span><span class="p">,</span>
                         <span class="s1">&#39;end_seq_token&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_end_seq_token</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">contents</span>

    <span class="k">def</span> <span class="nf">lookup_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieve the index associated with the token </span>
<span class="sd">          or the UNK index if token isn&#39;t present.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            token (str): the token to look up </span>
<span class="sd">        Returns:</span>
<span class="sd">            index (int): the index corresponding to the token</span>
<span class="sd">        Notes:</span>
<span class="sd">            `unk_index` needs to be &gt;=0 (having been added into the Vocabulary) </span>
<span class="sd">              for the UNK functionality </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk_index</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_to_idx</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">NMTVectorizer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; The Vectorizer which coordinates the Vocabularies and puts them to use&quot;&quot;&quot;</span>        
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_vocab</span><span class="p">,</span> <span class="n">target_vocab</span><span class="p">,</span> <span class="n">max_source_length</span><span class="p">,</span> <span class="n">max_target_length</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            source_vocab (SequenceVocabulary): maps source words to integers</span>
<span class="sd">            target_vocab (SequenceVocabulary): maps target words to integers</span>
<span class="sd">            max_source_length (int): the longest sequence in the source dataset</span>
<span class="sd">            max_target_length (int): the longest sequence in the target dataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">source_vocab</span> <span class="o">=</span> <span class="n">source_vocab</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_vocab</span> <span class="o">=</span> <span class="n">target_vocab</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">max_source_length</span> <span class="o">=</span> <span class="n">max_source_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_target_length</span> <span class="o">=</span> <span class="n">max_target_length</span>
        

    <span class="k">def</span> <span class="nf">_vectorize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">vector_length</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">mask_index</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Vectorize the provided indices</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            indices (list): a list of integers that represent a sequence</span>
<span class="sd">            vector_length (int): an argument for forcing the length of index vector</span>
<span class="sd">            mask_index (int): the mask_index to use; almost always 0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">vector_length</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">vector_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        
        <span class="n">vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">vector_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">vector</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)]</span> <span class="o">=</span> <span class="n">indices</span>
        <span class="n">vector</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">):]</span> <span class="o">=</span> <span class="n">mask_index</span>

        <span class="k">return</span> <span class="n">vector</span>
    
    <span class="k">def</span> <span class="nf">_get_source_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the vectorized source text</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            text (str): the source text; tokens should be separated by spaces</span>
<span class="sd">        Returns:</span>
<span class="sd">            indices (list): list of integers representing the text</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">source_vocab</span><span class="o">.</span><span class="n">begin_seq_index</span><span class="p">]</span>
        <span class="n">indices</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">source_vocab</span><span class="o">.</span><span class="n">lookup_token</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">))</span>
        <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">source_vocab</span><span class="o">.</span><span class="n">end_seq_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">indices</span>
    
    <span class="k">def</span> <span class="nf">_get_target_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the vectorized source text</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            text (str): the source text; tokens should be separated by spaces</span>
<span class="sd">        Returns:</span>
<span class="sd">            a tuple: (x_indices, y_indices)</span>
<span class="sd">                x_indices (list): list of integers representing the observations in target decoder </span>
<span class="sd">                y_indices (list): list of integers representing predictions in target decoder</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_vocab</span><span class="o">.</span><span class="n">lookup_token</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)]</span>
        <span class="n">x_indices</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_vocab</span><span class="o">.</span><span class="n">begin_seq_index</span><span class="p">]</span> <span class="o">+</span> <span class="n">indices</span>
        <span class="n">y_indices</span> <span class="o">=</span> <span class="n">indices</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_vocab</span><span class="o">.</span><span class="n">end_seq_index</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">x_indices</span><span class="p">,</span> <span class="n">y_indices</span>
        
    <span class="k">def</span> <span class="nf">vectorize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">,</span> <span class="n">use_dataset_max_lengths</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the vectorized source and target text</span>
<span class="sd">        </span>
<span class="sd">        The vetorized source text is just the a single vector.</span>
<span class="sd">        The vectorized target text is split into two vectors in a similar style to </span>
<span class="sd">            the surname modeling in Chapter 7.</span>
<span class="sd">        At each timestep, the first vector is the observation and the second vector is the target. </span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            source_text (str): text from the source language</span>
<span class="sd">            target_text (str): text from the target language</span>
<span class="sd">            use_dataset_max_lengths (bool): whether to use the global max vector lengths</span>
<span class="sd">        Returns:</span>
<span class="sd">            The vectorized data point as a dictionary with the keys: </span>
<span class="sd">                source_vector, target_x_vector, target_y_vector, source_length</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">source_vector_length</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">target_vector_length</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        
        <span class="k">if</span> <span class="n">use_dataset_max_lengths</span><span class="p">:</span>
            <span class="n">source_vector_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_source_length</span> <span class="o">+</span> <span class="mi">2</span>
            <span class="n">target_vector_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_target_length</span> <span class="o">+</span> <span class="mi">1</span>
            
        <span class="n">source_indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_source_indices</span><span class="p">(</span><span class="n">source_text</span><span class="p">)</span>
        <span class="n">source_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectorize</span><span class="p">(</span><span class="n">source_indices</span><span class="p">,</span> 
                                        <span class="n">vector_length</span><span class="o">=</span><span class="n">source_vector_length</span><span class="p">,</span> 
                                        <span class="n">mask_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">source_vocab</span><span class="o">.</span><span class="n">mask_index</span><span class="p">)</span>
        
        <span class="n">target_x_indices</span><span class="p">,</span> <span class="n">target_y_indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_target_indices</span><span class="p">(</span><span class="n">target_text</span><span class="p">)</span>
        <span class="n">target_x_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectorize</span><span class="p">(</span><span class="n">target_x_indices</span><span class="p">,</span>
                                        <span class="n">vector_length</span><span class="o">=</span><span class="n">target_vector_length</span><span class="p">,</span>
                                        <span class="n">mask_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_vocab</span><span class="o">.</span><span class="n">mask_index</span><span class="p">)</span>
        <span class="n">target_y_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectorize</span><span class="p">(</span><span class="n">target_y_indices</span><span class="p">,</span>
                                        <span class="n">vector_length</span><span class="o">=</span><span class="n">target_vector_length</span><span class="p">,</span>
                                        <span class="n">mask_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_vocab</span><span class="o">.</span><span class="n">mask_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;source_vector&quot;</span><span class="p">:</span> <span class="n">source_vector</span><span class="p">,</span> 
                <span class="s2">&quot;target_x_vector&quot;</span><span class="p">:</span> <span class="n">target_x_vector</span><span class="p">,</span> 
                <span class="s2">&quot;target_y_vector&quot;</span><span class="p">:</span> <span class="n">target_y_vector</span><span class="p">,</span> 
                <span class="s2">&quot;source_length&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_indices</span><span class="p">)}</span>
        
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_dataframe</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">bitext_df</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Instantiate the vectorizer from the dataset dataframe</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            bitext_df (pandas.DataFrame): the parallel text dataset</span>
<span class="sd">        Returns:</span>
<span class="sd">            an instance of the NMTVectorizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">source_vocab</span> <span class="o">=</span> <span class="n">SequenceVocabulary</span><span class="p">()</span>
        <span class="n">target_vocab</span> <span class="o">=</span> <span class="n">SequenceVocabulary</span><span class="p">()</span>
        
        <span class="n">max_source_length</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">max_target_length</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">bitext_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
            <span class="n">source_tokens</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;source_language&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_source_length</span><span class="p">:</span>
                <span class="n">max_source_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_tokens</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">source_tokens</span><span class="p">:</span>
                <span class="n">source_vocab</span><span class="o">.</span><span class="n">add_token</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
            
            <span class="n">target_tokens</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;target_language&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_target_length</span><span class="p">:</span>
                <span class="n">max_target_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_tokens</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">target_tokens</span><span class="p">:</span>
                <span class="n">target_vocab</span><span class="o">.</span><span class="n">add_token</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">source_vocab</span><span class="p">,</span> <span class="n">target_vocab</span><span class="p">,</span> <span class="n">max_source_length</span><span class="p">,</span> <span class="n">max_target_length</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_serializable</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">contents</span><span class="p">):</span>
        <span class="n">source_vocab</span> <span class="o">=</span> <span class="n">SequenceVocabulary</span><span class="o">.</span><span class="n">from_serializable</span><span class="p">(</span><span class="n">contents</span><span class="p">[</span><span class="s2">&quot;source_vocab&quot;</span><span class="p">])</span>
        <span class="n">target_vocab</span> <span class="o">=</span> <span class="n">SequenceVocabulary</span><span class="o">.</span><span class="n">from_serializable</span><span class="p">(</span><span class="n">contents</span><span class="p">[</span><span class="s2">&quot;target_vocab&quot;</span><span class="p">])</span>
        
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">source_vocab</span><span class="o">=</span><span class="n">source_vocab</span><span class="p">,</span> 
                   <span class="n">target_vocab</span><span class="o">=</span><span class="n">target_vocab</span><span class="p">,</span> 
                   <span class="n">max_source_length</span><span class="o">=</span><span class="n">contents</span><span class="p">[</span><span class="s2">&quot;max_source_length&quot;</span><span class="p">],</span> 
                   <span class="n">max_target_length</span><span class="o">=</span><span class="n">contents</span><span class="p">[</span><span class="s2">&quot;max_target_length&quot;</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">to_serializable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;source_vocab&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">source_vocab</span><span class="o">.</span><span class="n">to_serializable</span><span class="p">(),</span> 
                <span class="s2">&quot;target_vocab&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_vocab</span><span class="o">.</span><span class="n">to_serializable</span><span class="p">(),</span> 
                <span class="s2">&quot;max_source_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_source_length</span><span class="p">,</span>
                <span class="s2">&quot;max_target_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_target_length</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">NMTDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_df</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            surname_df (pandas.DataFrame): the dataset</span>
<span class="sd">            vectorizer (SurnameVectorizer): vectorizer instatiated from dataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_df</span> <span class="o">=</span> <span class="n">text_df</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_df</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">text_df</span><span class="o">.</span><span class="n">split</span><span class="o">==</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_df</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">val_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_df</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">text_df</span><span class="o">.</span><span class="n">split</span><span class="o">==</span><span class="s1">&#39;val&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validation_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_df</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">test_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_df</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">text_df</span><span class="o">.</span><span class="n">split</span><span class="o">==</span><span class="s1">&#39;test&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_df</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_lookup_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span><span class="p">),</span>
                             <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_size</span><span class="p">),</span>
                             <span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span><span class="p">)}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">load_dataset_and_make_vectorizer</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">dataset_csv</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load dataset and make a new vectorizer from scratch</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            surname_csv (str): location of the dataset</span>
<span class="sd">        Returns:</span>
<span class="sd">            an instance of SurnameDataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">text_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">dataset_csv</span><span class="p">)</span>
        <span class="n">train_subset</span> <span class="o">=</span> <span class="n">text_df</span><span class="p">[</span><span class="n">text_df</span><span class="o">.</span><span class="n">split</span><span class="o">==</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">text_df</span><span class="p">,</span> <span class="n">NMTVectorizer</span><span class="o">.</span><span class="n">from_dataframe</span><span class="p">(</span><span class="n">train_subset</span><span class="p">))</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">load_dataset_and_load_vectorizer</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">dataset_csv</span><span class="p">,</span> <span class="n">vectorizer_filepath</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load dataset and the corresponding vectorizer. </span>
<span class="sd">        Used in the case in the vectorizer has been cached for re-use</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            surname_csv (str): location of the dataset</span>
<span class="sd">            vectorizer_filepath (str): location of the saved vectorizer</span>
<span class="sd">        Returns:</span>
<span class="sd">            an instance of SurnameDataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">text_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">dataset_csv</span><span class="p">)</span>
        <span class="n">vectorizer</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">load_vectorizer_only</span><span class="p">(</span><span class="n">vectorizer_filepath</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">text_df</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">load_vectorizer_only</span><span class="p">(</span><span class="n">vectorizer_filepath</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;a static method for loading the vectorizer from file</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            vectorizer_filepath (str): the location of the serialized vectorizer</span>
<span class="sd">        Returns:</span>
<span class="sd">            an instance of SurnameVectorizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vectorizer_filepath</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">NMTVectorizer</span><span class="o">.</span><span class="n">from_serializable</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fp</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">save_vectorizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectorizer_filepath</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;saves the vectorizer to disk using json</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            vectorizer_filepath (str): the location to save the vectorizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vectorizer_filepath</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span><span class="o">.</span><span class="n">to_serializable</span><span class="p">(),</span> <span class="n">fp</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_vectorizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; returns the vectorizer &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span>

    <span class="k">def</span> <span class="nf">set_split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_target_split</span> <span class="o">=</span> <span class="n">split</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_target_df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lookup_dict</span><span class="p">[</span><span class="n">split</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target_size</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;the primary entry point method for PyTorch datasets</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            index (int): the index to the data point </span>
<span class="sd">        Returns:</span>
<span class="sd">            a dictionary holding the data point: (x_data, y_target, class_index)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">row</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

        <span class="n">vector_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">source_language</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">target_language</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;x_source&quot;</span><span class="p">:</span> <span class="n">vector_dict</span><span class="p">[</span><span class="s2">&quot;source_vector&quot;</span><span class="p">],</span> 
                <span class="s2">&quot;x_target&quot;</span><span class="p">:</span> <span class="n">vector_dict</span><span class="p">[</span><span class="s2">&quot;target_x_vector&quot;</span><span class="p">],</span>
                <span class="s2">&quot;y_target&quot;</span><span class="p">:</span> <span class="n">vector_dict</span><span class="p">[</span><span class="s2">&quot;target_y_vector&quot;</span><span class="p">],</span> 
                <span class="s2">&quot;x_source_length&quot;</span><span class="p">:</span> <span class="n">vector_dict</span><span class="p">[</span><span class="s2">&quot;source_length&quot;</span><span class="p">]}</span>
        
    <span class="k">def</span> <span class="nf">get_num_batches</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Given a batch size, return the number of batches in the dataset</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            batch_size (int)</span>
<span class="sd">        Returns:</span>
<span class="sd">            number of batches in the dataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_nmt_batches</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                            <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A generator function which wraps the PyTorch DataLoader.  The NMT Version &quot;&quot;&quot;</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">data_dict</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="s1">&#39;x_source_length&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">sorted_length_indices</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        
        <span class="n">out_data_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">out_data_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="n">sorted_length_indices</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">out_data_dict</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="neural-machine-translation-model">
<h1><span class="section-number">4. </span>Neural Machine Translation Model<a class="headerlink" href="#neural-machine-translation-model" title="Permalink to this headline"></a></h1>
<p>Components:</p>
<ol class="simple">
<li><p>NMTEncoder</p>
<ul class="simple">
<li><p>accepts as input a source sequence to be embedded and fed through a bi-directional GRU</p></li>
</ul>
</li>
<li><p>NMTDecoder</p>
<ul class="simple">
<li><p>using the encoder state and attention, the decoder generates a new sequence</p></li>
<li><p>the ground truth target sequence is used as input to the decoder at each time step</p></li>
<li><p>an alternative formulation would allow some of the decoders own choices to be used as input</p></li>
<li><p>this is referred to as curriculum learning, learning to search</p>
<ul>
<li><p>TODO: Look up references for this.  I believe Bengio has a paper from the image captioning competitions. Hal Daume has tons on this and is the main NLP guy for it.</p></li>
</ul>
</li>
</ul>
</li>
<li><p>NMTModel</p>
<ul class="simple">
<li><p>Combines the encoder and decoder into a single class.</p></li>
</ul>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">NMTEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_embeddings</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">rnn_hidden_size</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            num_embeddings (int): number of embeddings is the size of source vocabulary</span>
<span class="sd">            embedding_size (int): size of the embedding vectors</span>
<span class="sd">            rnn_hidden_size (int): size of the RNN hidden state vectors </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NMTEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    
        <span class="bp">self</span><span class="o">.</span><span class="n">source_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">birnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">embedding_size</span><span class="p">,</span> <span class="n">rnn_hidden_size</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_source</span><span class="p">,</span> <span class="n">x_lengths</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The forward pass of the model</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            x_source (torch.Tensor): the input data tensor.</span>
<span class="sd">                x_source.shape is (batch, seq_size)</span>
<span class="sd">            x_lengths (torch.Tensor): a vector of lengths for each item in the batch</span>
<span class="sd">        Returns:</span>
<span class="sd">            a tuple: x_unpacked (torch.Tensor), x_birnn_h (torch.Tensor)</span>
<span class="sd">                x_unpacked.shape = (batch, seq_size, rnn_hidden_size * 2)</span>
<span class="sd">                x_birnn_h.shape = (batch, rnn_hidden_size * 2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x_embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">source_embedding</span><span class="p">(</span><span class="n">x_source</span><span class="p">)</span>
        <span class="c1"># create PackedSequence; x_packed.data.shape=(number_items, embeddign_size)</span>
        <span class="n">x_packed</span> <span class="o">=</span> <span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">x_embedded</span><span class="p">,</span> <span class="n">x_lengths</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> 
                                        <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="c1"># x_birnn_h.shape = (num_rnn, batch_size, feature_size)</span>
        <span class="n">x_birnn_out</span><span class="p">,</span> <span class="n">x_birnn_h</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">birnn</span><span class="p">(</span><span class="n">x_packed</span><span class="p">)</span>
        <span class="c1"># permute to (batch_size, num_rnn, feature_size)</span>
        <span class="n">x_birnn_h</span> <span class="o">=</span> <span class="n">x_birnn_h</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        
        <span class="c1"># flatten features; reshape to (batch_size, num_rnn * feature_size)</span>
        <span class="c1">#  (recall: -1 takes the remaining positions, </span>
        <span class="c1">#           flattening the two RNN hidden vectors into 1)</span>
        <span class="n">x_birnn_h</span> <span class="o">=</span> <span class="n">x_birnn_h</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x_birnn_h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">x_unpacked</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">x_birnn_out</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x_unpacked</span><span class="p">,</span> <span class="n">x_birnn_h</span>

<span class="k">def</span> <span class="nf">verbose_attention</span><span class="p">(</span><span class="n">encoder_state_vectors</span><span class="p">,</span> <span class="n">query_vector</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A descriptive version of the neural attention mechanism </span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        encoder_state_vectors (torch.Tensor): 3dim tensor from bi-GRU in encoder</span>
<span class="sd">        query_vector (torch.Tensor): hidden state in decoder GRU</span>
<span class="sd">    Returns:</span>
<span class="sd">        </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_vectors</span><span class="p">,</span> <span class="n">vector_size</span> <span class="o">=</span> <span class="n">encoder_state_vectors</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
    <span class="n">vector_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">encoder_state_vectors</span> <span class="o">*</span> <span class="n">query_vector</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">vector_size</span><span class="p">),</span> 
                              <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">vector_probabilities</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">vector_scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">weighted_vectors</span> <span class="o">=</span> <span class="n">encoder_state_vectors</span> <span class="o">*</span> <span class="n">vector_probabilities</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_vectors</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">context_vectors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weighted_vectors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">context_vectors</span><span class="p">,</span> <span class="n">vector_probabilities</span><span class="p">,</span> <span class="n">vector_scores</span>

<span class="k">def</span> <span class="nf">terse_attention</span><span class="p">(</span><span class="n">encoder_state_vectors</span><span class="p">,</span> <span class="n">query_vector</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A shorter and more optimized version of the neural attention mechanism</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        encoder_state_vectors (torch.Tensor): 3dim tensor from bi-GRU in encoder</span>
<span class="sd">        query_vector (torch.Tensor): hidden state</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">vector_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">encoder_state_vectors</span><span class="p">,</span> <span class="n">query_vector</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="n">vector_probabilities</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">vector_scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">context_vectors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">encoder_state_vectors</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> 
                                   <span class="n">vector_probabilities</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">context_vectors</span><span class="p">,</span> <span class="n">vector_probabilities</span>


<span class="k">class</span> <span class="nc">NMTDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_embeddings</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">rnn_hidden_size</span><span class="p">,</span> <span class="n">bos_index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            num_embeddings (int): number of embeddings is also the number of </span>
<span class="sd">                unique words in target vocabulary </span>
<span class="sd">            embedding_size (int): the embedding vector size</span>
<span class="sd">            rnn_hidden_size (int): size of the hidden rnn state</span>
<span class="sd">            bos_index(int): begin-of-sequence index</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NMTDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_rnn_hidden_size</span> <span class="o">=</span> <span class="n">rnn_hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="n">num_embeddings</span><span class="p">,</span> 
                                             <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_size</span><span class="p">,</span> 
                                             <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru_cell</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="n">embedding_size</span> <span class="o">+</span> <span class="n">rnn_hidden_size</span><span class="p">,</span> 
                                   <span class="n">rnn_hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_map</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">rnn_hidden_size</span><span class="p">,</span> <span class="n">rnn_hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">rnn_hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num_embeddings</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bos_index</span> <span class="o">=</span> <span class="n">bos_index</span>
    
    <span class="k">def</span> <span class="nf">_init_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; return the BEGIN-OF-SEQUENCE index vector &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">bos_index</span>
    
    <span class="k">def</span> <span class="nf">_init_context_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; return a zeros vector for initializing the context &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rnn_hidden_size</span><span class="p">)</span>
            
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span> <span class="n">initial_hidden_state</span><span class="p">,</span> <span class="n">target_sequence</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The forward pass of the model</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            encoder_state (torch.Tensor): the output of the NMTEncoder</span>
<span class="sd">            initial_hidden_state (torch.Tensor): The last hidden state in the  NMTEncoder</span>
<span class="sd">            target_sequence (torch.Tensor): the target text data tensor</span>
<span class="sd">        Returns:</span>
<span class="sd">            output_vectors (torch.Tensor): prediction vectors at each output step</span>
<span class="sd">        &quot;&quot;&quot;</span>    
        <span class="c1"># We are making an assumption there: The batch is on first</span>
        <span class="c1"># The input is (Batch, Seq)</span>
        <span class="c1"># We want to iterate over sequence so we permute it to (S, B)</span>
        <span class="n">target_sequence</span> <span class="o">=</span> <span class="n">target_sequence</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">output_sequence_size</span> <span class="o">=</span> <span class="n">target_sequence</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># use the provided encoder hidden state as the initial hidden state</span>
        <span class="n">h_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_map</span><span class="p">(</span><span class="n">initial_hidden_state</span><span class="p">)</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">encoder_state</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># initialize context vectors to zeros</span>
        <span class="n">context_vectors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_context_vectors</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="c1"># initialize first y_t word as BOS</span>
        <span class="n">y_t_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_indices</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        
        <span class="n">h_t</span> <span class="o">=</span> <span class="n">h_t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">encoder_state</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">y_t_index</span> <span class="o">=</span> <span class="n">y_t_index</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">encoder_state</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">context_vectors</span> <span class="o">=</span> <span class="n">context_vectors</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">encoder_state</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">output_vectors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cached_p_attn</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cached_ht</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cached_decoder_state</span> <span class="o">=</span> <span class="n">encoder_state</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">output_sequence_size</span><span class="p">):</span>
            <span class="n">y_t_index</span> <span class="o">=</span> <span class="n">target_sequence</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                
            <span class="c1"># Step 1: Embed word and concat with previous context</span>
            <span class="n">y_input_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_embedding</span><span class="p">(</span><span class="n">y_t_index</span><span class="p">)</span>
            <span class="n">rnn_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">y_input_vector</span><span class="p">,</span> <span class="n">context_vectors</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="c1"># Step 2: Make a GRU step, getting a new hidden vector</span>
            <span class="n">h_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru_cell</span><span class="p">(</span><span class="n">rnn_input</span><span class="p">,</span> <span class="n">h_t</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_cached_ht</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">h_t</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            
            <span class="c1"># Step 3: Use the current hidden to attend to the encoder state</span>
            <span class="n">context_vectors</span><span class="p">,</span> <span class="n">p_attn</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">verbose_attention</span><span class="p">(</span><span class="n">encoder_state_vectors</span><span class="o">=</span><span class="n">encoder_state</span><span class="p">,</span> 
                                                           <span class="n">query_vector</span><span class="o">=</span><span class="n">h_t</span><span class="p">)</span>
            
            <span class="c1"># auxillary: cache the attention probabilities for visualization</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_cached_p_attn</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p_attn</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            
            <span class="c1"># Step 4: Use the current hidden and context vectors to make a prediction to the next word</span>
            <span class="n">prediction_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">context_vectors</span><span class="p">,</span> <span class="n">h_t</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">score_for_y_t_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">prediction_vector</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">))</span>
            
            <span class="c1"># auxillary: collect the prediction scores</span>
            <span class="n">output_vectors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score_for_y_t_index</span><span class="p">)</span>
            
        <span class="n">output_vectors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">output_vectors</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">output_vectors</span>
    
    
<span class="k">class</span> <span class="nc">NMTModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; The Neural Machine Translation Model &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">source_embedding_size</span><span class="p">,</span> 
                 <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">target_embedding_size</span><span class="p">,</span> <span class="n">encoding_size</span><span class="p">,</span> 
                 <span class="n">target_bos_index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            source_vocab_size (int): number of unique words in source language</span>
<span class="sd">            source_embedding_size (int): size of the source embedding vectors</span>
<span class="sd">            target_vocab_size (int): number of unique words in target language</span>
<span class="sd">            target_embedding_size (int): size of the target embedding vectors</span>
<span class="sd">            encoding_size (int): the size of the encoder RNN.  </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NMTModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">NMTEncoder</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="n">source_vocab_size</span><span class="p">,</span> 
                                  <span class="n">embedding_size</span><span class="o">=</span><span class="n">source_embedding_size</span><span class="p">,</span>
                                  <span class="n">rnn_hidden_size</span><span class="o">=</span><span class="n">encoding_size</span><span class="p">)</span>
        <span class="n">decoding_size</span> <span class="o">=</span> <span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">NMTDecoder</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="n">target_vocab_size</span><span class="p">,</span> 
                                  <span class="n">embedding_size</span><span class="o">=</span><span class="n">target_embedding_size</span><span class="p">,</span> 
                                  <span class="n">rnn_hidden_size</span><span class="o">=</span><span class="n">decoding_size</span><span class="p">,</span>
                                  <span class="n">bos_index</span><span class="o">=</span><span class="n">target_bos_index</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_source</span><span class="p">,</span> <span class="n">x_source_lengths</span><span class="p">,</span> <span class="n">target_sequence</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The forward pass of the model</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            x_source (torch.Tensor): the source text data tensor. </span>
<span class="sd">                x_source.shape should be (batch, vectorizer.max_source_length)</span>
<span class="sd">            x_source_lengths torch.Tensor): the length of the sequences in x_source </span>
<span class="sd">            target_sequence (torch.Tensor): the target text data tensor</span>
<span class="sd">        Returns:</span>
<span class="sd">            decoded_states (torch.Tensor): prediction vectors at each output step</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">encoder_state</span><span class="p">,</span> <span class="n">final_hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x_source</span><span class="p">,</span> <span class="n">x_source_lengths</span><span class="p">)</span>
        <span class="n">decoded_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">encoder_state</span><span class="o">=</span><span class="n">encoder_state</span><span class="p">,</span> 
                                      <span class="n">initial_hidden_state</span><span class="o">=</span><span class="n">final_hidden_states</span><span class="p">,</span> 
                                      <span class="n">target_sequence</span><span class="o">=</span><span class="n">target_sequence</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">decoded_states</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="training-routine-and-bookkeeping-functions">
<h1><span class="section-number">5. </span>Training Routine and Bookkeeping Functions<a class="headerlink" href="#training-routine-and-bookkeeping-functions" title="Permalink to this headline"></a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">set_seed_everywhere</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">cuda</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cuda</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">handle_dirs</span><span class="p">(</span><span class="n">dirpath</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dirpath</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dirpath</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">make_train_state</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;stop_early&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s1">&#39;early_stopping_step&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s1">&#39;early_stopping_best_val&#39;</span><span class="p">:</span> <span class="mf">1e8</span><span class="p">,</span>
            <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="s1">&#39;epoch_index&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s1">&#39;train_acc&#39;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s1">&#39;val_acc&#39;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s1">&#39;test_loss&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
            <span class="s1">&#39;test_acc&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
            <span class="s1">&#39;model_filename&#39;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">model_state_file</span><span class="p">}</span>

<span class="k">def</span> <span class="nf">update_train_state</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_state</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Handle the training state updates.</span>
<span class="sd">    Components:</span>
<span class="sd">     - Early Stopping: Prevent overfitting.</span>
<span class="sd">     - Model Checkpoint: Model is saved if the model is better</span>
<span class="sd">    </span>
<span class="sd">    :param args: main arguments</span>
<span class="sd">    :param model: model to train</span>
<span class="sd">    :param train_state: a dictionary representing the training state values</span>
<span class="sd">    :returns:</span>
<span class="sd">        a new train_state</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Save one model at least</span>
    <span class="k">if</span> <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;epoch_index&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;model_filename&#39;</span><span class="p">])</span>
        <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;stop_early&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Save model if performance improved</span>
    <span class="k">elif</span> <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;epoch_index&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">loss_tm1</span><span class="p">,</span> <span class="n">loss_t</span> <span class="o">=</span> <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
         
        <span class="c1"># If loss worsened</span>
        <span class="k">if</span> <span class="n">loss_t</span> <span class="o">&gt;=</span> <span class="n">loss_tm1</span><span class="p">:</span>
            <span class="c1"># Update step</span>
            <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;early_stopping_step&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># Loss decreased</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Save the best model</span>
            <span class="k">if</span> <span class="n">loss_t</span> <span class="o">&lt;</span> <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;early_stopping_best_val&#39;</span><span class="p">]:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;model_filename&#39;</span><span class="p">])</span>
                <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;early_stopping_best_val&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_t</span>

            <span class="c1"># Reset early stopping step</span>
            <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;early_stopping_step&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Stop early ?</span>
        <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;stop_early&#39;</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;early_stopping_step&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">args</span><span class="o">.</span><span class="n">early_stopping_criteria</span>

    <span class="k">return</span> <span class="n">train_state</span>

<span class="k">def</span> <span class="nf">normalize_sizes</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Normalize tensor sizes</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        y_pred (torch.Tensor): the output of the model</span>
<span class="sd">            If a 3-dimensional tensor, reshapes to a matrix</span>
<span class="sd">        y_true (torch.Tensor): the target predictions</span>
<span class="sd">            If a matrix, reshapes to be a vector</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span>

<span class="k">def</span> <span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">mask_index</span><span class="p">):</span>
    <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">normalize_sizes</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">y_pred_indices</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">correct_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y_pred_indices</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">valid_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">mask_index</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    
    <span class="n">n_correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">correct_indices</span> <span class="o">*</span> <span class="n">valid_indices</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">n_valid</span> <span class="o">=</span> <span class="n">valid_indices</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">n_correct</span> <span class="o">/</span> <span class="n">n_valid</span> <span class="o">*</span> <span class="mi">100</span>

<span class="k">def</span> <span class="nf">sequence_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">mask_index</span><span class="p">):</span>
    <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">normalize_sizes</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="n">mask_index</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">args</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span><span class="n">dataset_csv</span><span class="o">=</span><span class="s2">&quot;data/nmt/simplest_eng_fra.csv&quot;</span><span class="p">,</span>
                 <span class="n">vectorizer_file</span><span class="o">=</span><span class="s2">&quot;vectorizer.json&quot;</span><span class="p">,</span>
                 <span class="n">model_state_file</span><span class="o">=</span><span class="s2">&quot;model.pth&quot;</span><span class="p">,</span>
                 <span class="n">save_dir</span><span class="o">=</span><span class="s2">&quot;model_storage/ch8/nmt_luong_no_sampling&quot;</span><span class="p">,</span>
                 <span class="n">reload_from_files</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">expand_filepaths_to_save_dir</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">seed</span><span class="o">=</span><span class="mi">1337</span><span class="p">,</span>
                 <span class="n">learning_rate</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">,</span>
                 <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                 <span class="n">num_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                 <span class="n">early_stopping_criteria</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>              
                 <span class="n">source_embedding_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> 
                 <span class="n">target_embedding_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                 <span class="n">encoding_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                 <span class="n">catch_keyboard_interrupt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">expand_filepaths_to_save_dir</span><span class="p">:</span>
    <span class="n">args</span><span class="o">.</span><span class="n">vectorizer_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">save_dir</span><span class="p">,</span>
                                        <span class="n">args</span><span class="o">.</span><span class="n">vectorizer_file</span><span class="p">)</span>

    <span class="n">args</span><span class="o">.</span><span class="n">model_state_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">save_dir</span><span class="p">,</span>
                                         <span class="n">args</span><span class="o">.</span><span class="n">model_state_file</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Expanded filepaths: &quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">vectorizer_file</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">model_state_file</span><span class="p">))</span>
    
<span class="c1"># Check CUDA</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">args</span><span class="o">.</span><span class="n">cuda</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">args</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">cuda</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
    
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Using CUDA: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">cuda</span><span class="p">))</span>

<span class="c1"># Set seed for reproducibility</span>
<span class="n">set_seed_everywhere</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">cuda</span><span class="p">)</span>

<span class="c1"># handle dirs</span>
<span class="n">handle_dirs</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">save_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Expanded filepaths: 
	model_storage/ch8/nmt_luong_no_sampling/vectorizer.json
	model_storage/ch8/nmt_luong_no_sampling/model.pth
Using CUDA: False
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">reload_from_files</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">vectorizer_file</span><span class="p">):</span>
    <span class="c1"># training from a checkpoint</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">NMTDataset</span><span class="o">.</span><span class="n">load_dataset_and_load_vectorizer</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dataset_csv</span><span class="p">,</span>
                                                          <span class="n">args</span><span class="o">.</span><span class="n">vectorizer_file</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># create dataset and vectorizer</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">NMTDataset</span><span class="o">.</span><span class="n">load_dataset_and_make_vectorizer</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dataset_csv</span><span class="p">)</span>
    <span class="n">dataset</span><span class="o">.</span><span class="n">save_vectorizer</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">vectorizer_file</span><span class="p">)</span>

<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_vectorizer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">NMTModel</span><span class="p">(</span><span class="n">source_vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">source_vocab</span><span class="p">),</span> 
                 <span class="n">source_embedding_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">source_embedding_size</span><span class="p">,</span> 
                 <span class="n">target_vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">target_vocab</span><span class="p">),</span>
                 <span class="n">target_embedding_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">target_embedding_size</span><span class="p">,</span> 
                 <span class="n">encoding_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">encoding_size</span><span class="p">,</span>
                 <span class="n">target_bos_index</span><span class="o">=</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">target_vocab</span><span class="o">.</span><span class="n">begin_seq_index</span><span class="p">)</span>

<span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">reload_from_files</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">model_state_file</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">model_state_file</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reloaded model&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;New model&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>New model
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                                           <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                                           <span class="n">patience</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">mask_index</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">target_vocab</span><span class="o">.</span><span class="n">mask_index</span>
<span class="n">train_state</span> <span class="o">=</span> <span class="n">make_train_state</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

<span class="n">epoch_bar</span> <span class="o">=</span> <span class="n">tqdm_notebook</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="s1">&#39;training routine&#39;</span><span class="p">,</span> 
                          <span class="n">total</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">,</span>
                          <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">train_bar</span> <span class="o">=</span> <span class="n">tqdm_notebook</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="s1">&#39;split=train&#39;</span><span class="p">,</span>
                          <span class="n">total</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_num_batches</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">),</span> 
                          <span class="n">position</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                          <span class="n">leave</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s1">&#39;val&#39;</span><span class="p">)</span>
<span class="n">val_bar</span> <span class="o">=</span> <span class="n">tqdm_notebook</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="s1">&#39;split=val&#39;</span><span class="p">,</span>
                        <span class="n">total</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_num_batches</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">),</span> 
                        <span class="n">position</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                        <span class="n">leave</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">epoch_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;epoch_index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch_index</span>

        <span class="c1"># Iterate over training dataset</span>

        <span class="c1"># setup: batch generator, set loss and acc to 0, set train mode on</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
        <span class="n">batch_generator</span> <span class="o">=</span> <span class="n">generate_nmt_batches</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> 
                                               <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> 
                                               <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">running_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        
        <span class="k">for</span> <span class="n">batch_index</span><span class="p">,</span> <span class="n">batch_dict</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">):</span>
            <span class="c1"># the training routine is these 5 steps:</span>

            <span class="c1"># --------------------------------------    </span>
            <span class="c1"># step 1. zero the gradients</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># step 2. compute the output</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_source&#39;</span><span class="p">],</span> 
                           <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_source_length&#39;</span><span class="p">],</span> 
                           <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_target&#39;</span><span class="p">])</span>

            <span class="c1"># step 3. compute the loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">sequence_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">],</span> <span class="n">mask_index</span><span class="p">)</span>

            <span class="c1"># step 4. use loss to produce gradients</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="c1"># step 5. use optimizer to take gradient step</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="c1"># -----------------------------------------</span>
            <span class="c1"># compute the running loss and running accuracy</span>
            <span class="n">running_loss</span> <span class="o">+=</span> <span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">-</span> <span class="n">running_loss</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">acc_t</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">],</span> <span class="n">mask_index</span><span class="p">)</span>
            <span class="n">running_acc</span> <span class="o">+=</span> <span class="p">(</span><span class="n">acc_t</span> <span class="o">-</span> <span class="n">running_acc</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            
            <span class="c1"># update bar</span>
            <span class="n">train_bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">running_loss</span><span class="p">,</span> <span class="n">acc</span><span class="o">=</span><span class="n">running_acc</span><span class="p">,</span> 
                            <span class="n">epoch</span><span class="o">=</span><span class="n">epoch_index</span><span class="p">)</span>
            <span class="n">train_bar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

        <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_loss</span><span class="p">)</span>
        <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;train_acc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_acc</span><span class="p">)</span>

        <span class="c1"># Iterate over val dataset</span>

        <span class="c1"># setup: batch generator, set loss and acc to 0; set eval mode on</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s1">&#39;val&#39;</span><span class="p">)</span>
        <span class="n">batch_generator</span> <span class="o">=</span> <span class="n">generate_nmt_batches</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> 
                                               <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> 
                                               <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="n">running_acc</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">batch_index</span><span class="p">,</span> <span class="n">batch_dict</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">):</span>
            <span class="c1"># compute the output</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_source&#39;</span><span class="p">],</span> 
                           <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_source_length&#39;</span><span class="p">],</span> 
                           <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_target&#39;</span><span class="p">])</span>

            <span class="c1"># step 3. compute the loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">sequence_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">],</span> <span class="n">mask_index</span><span class="p">)</span>

            <span class="c1"># compute the running loss and accuracy</span>
            <span class="n">running_loss</span> <span class="o">+=</span> <span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">-</span> <span class="n">running_loss</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            
            <span class="n">acc_t</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">],</span> <span class="n">mask_index</span><span class="p">)</span>
            <span class="n">running_acc</span> <span class="o">+=</span> <span class="p">(</span><span class="n">acc_t</span> <span class="o">-</span> <span class="n">running_acc</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            
            <span class="c1"># Update bar</span>
            <span class="n">val_bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">running_loss</span><span class="p">,</span> <span class="n">acc</span><span class="o">=</span><span class="n">running_acc</span><span class="p">,</span> 
                            <span class="n">epoch</span><span class="o">=</span><span class="n">epoch_index</span><span class="p">)</span>
            <span class="n">val_bar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

        <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_loss</span><span class="p">)</span>
        <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;val_acc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_acc</span><span class="p">)</span>

        <span class="n">train_state</span> <span class="o">=</span> <span class="n">update_train_state</span><span class="p">(</span><span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> 
                                         <span class="n">train_state</span><span class="o">=</span><span class="n">train_state</span><span class="p">)</span>

        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;stop_early&#39;</span><span class="p">]:</span>
            <span class="k">break</span>
            
        <span class="n">train_bar</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">val_bar</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">epoch_bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">best_val</span><span class="o">=</span><span class="n">train_state</span><span class="p">[</span><span class="s1">&#39;early_stopping_best_val&#39;</span><span class="p">]</span> <span class="p">)</span>
        <span class="n">epoch_bar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
        
<span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Exiting loop&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "e4c6282bbde04870b128e96ef0da9260", "version_major": 2, "version_minor": 0}
</script><script type="application/vnd.jupyter.widget-view+json">
{"model_id": "cd0bb05dd6c04295bd2e4702de6fb961", "version_major": 2, "version_minor": 0}
</script><script type="application/vnd.jupyter.widget-view+json">
{"model_id": "bec25a08e7994b9281bc44f324067aed", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Exiting loop
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>NMTModel(
  (encoder): NMTEncoder(
    (source_embedding): Embedding(3025, 64, padding_idx=0)
    (birnn): GRU(64, 64, batch_first=True, bidirectional=True)
  )
  (decoder): NMTDecoder(
    (target_embedding): Embedding(4902, 64, padding_idx=0)
    (gru_cell): GRUCell(192, 128)
    (hidden_map): Linear(in_features=128, out_features=128, bias=True)
    (classifier): Linear(in_features=256, out_features=4902, bias=True)
  )
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.translate</span> <span class="kn">import</span> <span class="n">bleu_score</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">chencherry</span> <span class="o">=</span> <span class="n">bleu_score</span><span class="o">.</span><span class="n">SmoothingFunction</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sentence_from_indices</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_string</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">ignore_indices</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="n">vocab</span><span class="o">.</span><span class="n">mask_index</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">begin_seq_index</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">end_seq_index</span><span class="p">])</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">index</span> <span class="o">==</span> <span class="n">vocab</span><span class="o">.</span><span class="n">begin_seq_index</span> <span class="ow">and</span> <span class="n">strict</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">elif</span> <span class="n">index</span> <span class="o">==</span> <span class="n">vocab</span><span class="o">.</span><span class="n">end_seq_index</span> <span class="ow">and</span> <span class="n">strict</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">lookup_index</span><span class="p">(</span><span class="n">index</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">return_string</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">out</span>
    
<span class="k">class</span> <span class="nc">NMTSampler</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    
    <span class="k">def</span> <span class="nf">apply_to_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch</span> <span class="o">=</span> <span class="n">batch_dict</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x_source</span><span class="o">=</span><span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_source&#39;</span><span class="p">],</span> 
                            <span class="n">x_source_lengths</span><span class="o">=</span><span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_source_length&#39;</span><span class="p">],</span> 
                            <span class="n">target_sequence</span><span class="o">=</span><span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_target&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch</span><span class="p">[</span><span class="s1">&#39;y_pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pred</span>
        
        <span class="n">attention_batched</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">_cached_p_attn</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch</span><span class="p">[</span><span class="s1">&#39;attention&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">attention_batched</span>
        
    <span class="k">def</span> <span class="nf">_get_source_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">return_string</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch</span><span class="p">[</span><span class="s1">&#39;x_source&#39;</span><span class="p">][</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">source_vocab</span>
        <span class="k">return</span> <span class="n">sentence_from_indices</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">return_string</span><span class="o">=</span><span class="n">return_string</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_reference_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">return_string</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">][</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">target_vocab</span>
        <span class="k">return</span> <span class="n">sentence_from_indices</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">return_string</span><span class="o">=</span><span class="n">return_string</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_get_sampled_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">return_string</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">all_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_last_batch</span><span class="p">[</span><span class="s1">&#39;y_pred&#39;</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">sentence_indices</span> <span class="o">=</span> <span class="n">all_indices</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">target_vocab</span>
        <span class="k">return</span> <span class="n">sentence_from_indices</span><span class="p">(</span><span class="n">sentence_indices</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">return_string</span><span class="o">=</span><span class="n">return_string</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_ith_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">return_string</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_source_sentence</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">return_string</span><span class="o">=</span><span class="n">return_string</span><span class="p">),</span> 
                  <span class="s2">&quot;reference&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_reference_sentence</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">return_string</span><span class="o">=</span><span class="n">return_string</span><span class="p">),</span> 
                  <span class="s2">&quot;sampled&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_sampled_sentence</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">return_string</span><span class="o">=</span><span class="n">return_string</span><span class="p">),</span>
                  <span class="s2">&quot;attention&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch</span><span class="p">[</span><span class="s1">&#39;attention&#39;</span><span class="p">][</span><span class="n">index</span><span class="p">]}</span>
        
        <span class="n">reference</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;reference&#39;</span><span class="p">]</span>
        <span class="n">hypothesis</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;sampled&#39;</span><span class="p">]</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_string</span><span class="p">:</span>
            <span class="n">reference</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">reference</span><span class="p">)</span>
            <span class="n">hypothesis</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
        
        <span class="n">output</span><span class="p">[</span><span class="s1">&#39;bleu-4&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bleu_score</span><span class="o">.</span><span class="n">sentence_bleu</span><span class="p">(</span><span class="n">references</span><span class="o">=</span><span class="p">[</span><span class="n">reference</span><span class="p">],</span>
                                                    <span class="n">hypothesis</span><span class="o">=</span><span class="n">hypothesis</span><span class="p">,</span>
                                                    <span class="n">smoothing_function</span><span class="o">=</span><span class="n">chencherry</span><span class="o">.</span><span class="n">method1</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="n">sampler</span> <span class="o">=</span> <span class="n">NMTSampler</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
<span class="n">batch_generator</span> <span class="o">=</span> <span class="n">generate_nmt_batches</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> 
                                       <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> 
                                       <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="n">test_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">batch_dict</span> <span class="ow">in</span> <span class="n">batch_generator</span><span class="p">:</span>
    <span class="n">sampler</span><span class="o">.</span><span class="n">apply_to_batch</span><span class="p">(</span><span class="n">batch_dict</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">test_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sampler</span><span class="o">.</span><span class="n">get_ith_item</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;bleu-4&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">test_results</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">);</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;bleu-4&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">test_results</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;bleu-4&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">test_results</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.25407270926974085, 0.238016853527947)
</pre></div>
</div>
<img alt="../_images/NMT_No_Sampling_18_1.png" src="../_images/NMT_No_Sampling_18_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">set_split</span><span class="p">(</span><span class="s1">&#39;val&#39;</span><span class="p">)</span>
<span class="n">batch_generator</span> <span class="o">=</span> <span class="n">generate_nmt_batches</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> 
                                       <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> 
                                       <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="n">batch_dict</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">NMTSampler</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="n">sampler</span><span class="o">.</span><span class="n">apply_to_batch</span><span class="p">(</span><span class="n">batch_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">all_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="n">all_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sampler</span><span class="o">.</span><span class="n">get_ith_item</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">top_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">all_results</span> <span class="k">if</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;bleu-4&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="mf">0.1</span><span class="p">]</span>
<span class="nb">len</span><span class="p">(</span><span class="n">top_results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>54
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">top_results</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">target_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;sampled&#39;</span><span class="p">])</span>
    <span class="n">source_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">])</span>

    <span class="n">attention_matrix</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s1">&#39;attention&#39;</span><span class="p">][:</span><span class="n">target_len</span><span class="p">,</span> <span class="p">:</span><span class="n">source_len</span><span class="o">+</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span><span class="c1">#[::-1]</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">attention_matrix</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
    <span class="n">ylabs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&lt;BOS&gt;&quot;</span><span class="p">]</span><span class="o">+</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="s2">&quot;&lt;EOS&gt;&quot;</span><span class="p">]</span>
    <span class="c1">#ylabs = sample[&#39;source&#39;]</span>
    <span class="c1">#ylabs = ylabs[::-1]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">ylabs</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;sampled&#39;</span><span class="p">],</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Target Sentence&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Source Sentence</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/brian/anaconda3/envs/nlpbook/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
</pre></div>
</div>
<img alt="../_images/NMT_No_Sampling_22_1.png" src="../_images/NMT_No_Sampling_22_1.png" />
<img alt="../_images/NMT_No_Sampling_22_2.png" src="../_images/NMT_No_Sampling_22_2.png" />
<img alt="../_images/NMT_No_Sampling_22_3.png" src="../_images/NMT_No_Sampling_22_3.png" />
<img alt="../_images/NMT_No_Sampling_22_4.png" src="../_images/NMT_No_Sampling_22_4.png" />
<img alt="../_images/NMT_No_Sampling_22_5.png" src="../_images/NMT_No_Sampling_22_5.png" />
<img alt="../_images/NMT_No_Sampling_22_6.png" src="../_images/NMT_No_Sampling_22_6.png" />
<img alt="../_images/NMT_No_Sampling_22_7.png" src="../_images/NMT_No_Sampling_22_7.png" />
<img alt="../_images/NMT_No_Sampling_22_8.png" src="../_images/NMT_No_Sampling_22_8.png" />
<img alt="../_images/NMT_No_Sampling_22_9.png" src="../_images/NMT_No_Sampling_22_9.png" />
<img alt="../_images/NMT_No_Sampling_22_10.png" src="../_images/NMT_No_Sampling_22_10.png" />
<img alt="../_images/NMT_No_Sampling_22_11.png" src="../_images/NMT_No_Sampling_22_11.png" />
<img alt="../_images/NMT_No_Sampling_22_12.png" src="../_images/NMT_No_Sampling_22_12.png" />
<img alt="../_images/NMT_No_Sampling_22_13.png" src="../_images/NMT_No_Sampling_22_13.png" />
<img alt="../_images/NMT_No_Sampling_22_14.png" src="../_images/NMT_No_Sampling_22_14.png" />
<img alt="../_images/NMT_No_Sampling_22_15.png" src="../_images/NMT_No_Sampling_22_15.png" />
<img alt="../_images/NMT_No_Sampling_22_16.png" src="../_images/NMT_No_Sampling_22_16.png" />
<img alt="../_images/NMT_No_Sampling_22_17.png" src="../_images/NMT_No_Sampling_22_17.png" />
<img alt="../_images/NMT_No_Sampling_22_18.png" src="../_images/NMT_No_Sampling_22_18.png" />
<img alt="../_images/NMT_No_Sampling_22_19.png" src="../_images/NMT_No_Sampling_22_19.png" />
<img alt="../_images/NMT_No_Sampling_22_20.png" src="../_images/NMT_No_Sampling_22_20.png" />
<img alt="../_images/NMT_No_Sampling_22_21.png" src="../_images/NMT_No_Sampling_22_21.png" />
<img alt="../_images/NMT_No_Sampling_22_22.png" src="../_images/NMT_No_Sampling_22_22.png" />
<img alt="../_images/NMT_No_Sampling_22_23.png" src="../_images/NMT_No_Sampling_22_23.png" />
<img alt="../_images/NMT_No_Sampling_22_24.png" src="../_images/NMT_No_Sampling_22_24.png" />
<img alt="../_images/NMT_No_Sampling_22_25.png" src="../_images/NMT_No_Sampling_22_25.png" />
<img alt="../_images/NMT_No_Sampling_22_26.png" src="../_images/NMT_No_Sampling_22_26.png" />
<img alt="../_images/NMT_No_Sampling_22_27.png" src="../_images/NMT_No_Sampling_22_27.png" />
<img alt="../_images/NMT_No_Sampling_22_28.png" src="../_images/NMT_No_Sampling_22_28.png" />
<img alt="../_images/NMT_No_Sampling_22_29.png" src="../_images/NMT_No_Sampling_22_29.png" />
<img alt="../_images/NMT_No_Sampling_22_30.png" src="../_images/NMT_No_Sampling_22_30.png" />
<img alt="../_images/NMT_No_Sampling_22_31.png" src="../_images/NMT_No_Sampling_22_31.png" />
<img alt="../_images/NMT_No_Sampling_22_32.png" src="../_images/NMT_No_Sampling_22_32.png" />
<img alt="../_images/NMT_No_Sampling_22_33.png" src="../_images/NMT_No_Sampling_22_33.png" />
<img alt="../_images/NMT_No_Sampling_22_34.png" src="../_images/NMT_No_Sampling_22_34.png" />
<img alt="../_images/NMT_No_Sampling_22_35.png" src="../_images/NMT_No_Sampling_22_35.png" />
<img alt="../_images/NMT_No_Sampling_22_36.png" src="../_images/NMT_No_Sampling_22_36.png" />
<img alt="../_images/NMT_No_Sampling_22_37.png" src="../_images/NMT_No_Sampling_22_37.png" />
<img alt="../_images/NMT_No_Sampling_22_38.png" src="../_images/NMT_No_Sampling_22_38.png" />
<img alt="../_images/NMT_No_Sampling_22_39.png" src="../_images/NMT_No_Sampling_22_39.png" />
<img alt="../_images/NMT_No_Sampling_22_40.png" src="../_images/NMT_No_Sampling_22_40.png" />
<img alt="../_images/NMT_No_Sampling_22_41.png" src="../_images/NMT_No_Sampling_22_41.png" />
<img alt="../_images/NMT_No_Sampling_22_42.png" src="../_images/NMT_No_Sampling_22_42.png" />
<img alt="../_images/NMT_No_Sampling_22_43.png" src="../_images/NMT_No_Sampling_22_43.png" />
<img alt="../_images/NMT_No_Sampling_22_44.png" src="../_images/NMT_No_Sampling_22_44.png" />
<img alt="../_images/NMT_No_Sampling_22_45.png" src="../_images/NMT_No_Sampling_22_45.png" />
<img alt="../_images/NMT_No_Sampling_22_46.png" src="../_images/NMT_No_Sampling_22_46.png" />
<img alt="../_images/NMT_No_Sampling_22_47.png" src="../_images/NMT_No_Sampling_22_47.png" />
<img alt="../_images/NMT_No_Sampling_22_48.png" src="../_images/NMT_No_Sampling_22_48.png" />
<img alt="../_images/NMT_No_Sampling_22_49.png" src="../_images/NMT_No_Sampling_22_49.png" />
<img alt="../_images/NMT_No_Sampling_22_50.png" src="../_images/NMT_No_Sampling_22_50.png" />
<img alt="../_images/NMT_No_Sampling_22_51.png" src="../_images/NMT_No_Sampling_22_51.png" />
<img alt="../_images/NMT_No_Sampling_22_52.png" src="../_images/NMT_No_Sampling_22_52.png" />
<img alt="../_images/NMT_No_Sampling_22_53.png" src="../_images/NMT_No_Sampling_22_53.png" />
<img alt="../_images/NMT_No_Sampling_22_54.png" src="../_images/NMT_No_Sampling_22_54.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_source_sentence</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_source&#39;</span><span class="p">][</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">source_vocab</span>
    <span class="k">return</span> <span class="n">sentence_from_indices</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">vocab</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_true_sentence</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sentence_from_indices</span><span class="p">(</span><span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;y_target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="n">index</span><span class="p">],</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">target_vocab</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">get_sampled_sentence</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_source</span><span class="o">=</span><span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_source&#39;</span><span class="p">],</span> 
                   <span class="n">x_source_lengths</span><span class="o">=</span><span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_source_length&#39;</span><span class="p">],</span> 
                   <span class="n">target_sequence</span><span class="o">=</span><span class="n">batch_dict</span><span class="p">[</span><span class="s1">&#39;x_target&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">sentence_from_indices</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="n">index</span><span class="p">],</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">target_vocab</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_all_sentences</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="n">get_source_sentence</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">,</span> <span class="n">index</span><span class="p">),</span> 
            <span class="s2">&quot;truth&quot;</span><span class="p">:</span> <span class="n">get_true_sentence</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">,</span> <span class="n">index</span><span class="p">),</span> 
            <span class="s2">&quot;sampled&quot;</span><span class="p">:</span> <span class="n">get_sampled_sentence</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">,</span> <span class="n">index</span><span class="p">)}</span>
    
<span class="k">def</span> <span class="nf">sentence_from_indices</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">ignore_indices</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="n">vocab</span><span class="o">.</span><span class="n">mask_index</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">begin_seq_index</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">end_seq_index</span><span class="p">])</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">index</span> <span class="o">==</span> <span class="n">vocab</span><span class="o">.</span><span class="n">begin_seq_index</span> <span class="ow">and</span> <span class="n">strict</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">elif</span> <span class="n">index</span> <span class="o">==</span> <span class="n">vocab</span><span class="o">.</span><span class="n">end_seq_index</span> <span class="ow">and</span> <span class="n">strict</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">lookup_index</span><span class="p">(</span><span class="n">index</span><span class="p">))</span>
    <span class="k">return</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">get_all_sentences</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">,</span> <span class="n">batch_dict</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;source&#39;: &quot;i &#39;m not going to tell you how to do that .&quot;,
 &#39;truth&#39;: &#39;je ne vais pas te dire comment le faire .&#39;,
 &#39;sampled&#39;: &#39;je suis suis pas de de de . . .&#39;}
</pre></div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "executablebooks/jupyter-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "nlpbook"
        },
        kernelOptions: {
            kernelName: "nlpbook",
            path: "./attention"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'nlpbook'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="PackedSequence.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">&lt;no title&gt;</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="NMT_scheduled_sampling.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title"><span class="section-number">6. </span>Neural Machine Translation Model</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By A/Prof. Wei Liu<br/>
        
            &copy; Copyright UWA 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>